{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd13f269-f13e-4fd4-99ff-0f460ab9a6d2",
   "metadata": {},
   "source": [
    "# EDA of Yahoo Stock Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053aea0-ff72-487d-94bf-07a8fbfdb9d6",
   "metadata": {},
   "source": [
    "This project focused on developing predictive models for stock prices using data from the Yahoo Finance API. Three forecasting methods were employed: Multiple Linear Regression, Time Series Regression, and Nonseasonal Box-Jenkins Models. The analysis involved addressing multicollinearity, assessing autocorrelation, and applying advanced statistical techniques like Lasso Regression to enhance model accuracy. Each method provided unique insights into stock price trends, revealing their potential in financial forecasting. Future work will integrate these methods and explore external factors to improve predictive capabilities. The complete report detailing methodologies and findings is available below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc231b-a9ed-4dc2-8d72-ec08e82872cc",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaf2aae-cc54-42d8-9c5e-08bf8e882157",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"790\"\n",
       "            height=\"1000\"\n",
       "            src=\"../_static/EDA of Yahoo Stock Price Prediction.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1034ddf90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../_static/EDA of Yahoo Stock Price Prediction.pdf\", width=790, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e0cec-af3f-490c-a2c0-0dea19c1c267",
   "metadata": {},
   "source": [
    "## R Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9a6f9f8-5457-4eac-89a9-69ab4591240a",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (523487179.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    time = data$Date\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "setwd(\"~/Desktop/ISYE4031/\")\n",
    "data = read.csv(\"yahoo_stock.csv\", header = TRUE)[1:1460,]\n",
    "return_data = read.csv(\"return_yahoo.csv\", header = TRUE)[1:1460,]\n",
    "\n",
    "time = data$Date\n",
    "high = data$High\n",
    "low = data$Low\n",
    "open = data$Open\n",
    "close = data$Close\n",
    "volume = data$Volume\n",
    "adj_close = data$Adj.Close\n",
    "\n",
    "# Multiple Linear Regression\n",
    "z = lm(high~low+open+close+volume)\n",
    "plot(high~low+open+close+volume)\n",
    "abline(lm(high~volume), col = \"red\")\n",
    "summary(lm(high~low+open+close+volume))\n",
    "anova(lm(high~low+open+close+volume))\n",
    "\n",
    "# VIF for each predictor\n",
    "install.packages(\"car\")\n",
    "library(car)\n",
    "data$average = rowMeans(data[, c(\"Low\", \"Open\", \"Close\")])\n",
    "average = data$average\n",
    "summary(lm(high~average+volume))\n",
    "\n",
    "vif_values = vif(lm(high~average +volume))\n",
    "vif_values\n",
    "\n",
    "# PCA\n",
    "standardized_data <- scale(data[, c(\"High\", \"Low\", \"Open\", \"Close\", \"Volume\")])\n",
    "pca_result <- prcomp(standardized_data)\n",
    "summary(pca_result)\n",
    "num_components <- 4\n",
    "data_transformed <- as.data.frame(predict(pca_result, newdata = standardized_data)[, 1:num_components])\n",
    "data_for_regression <- cbind(data_transformed, high = data$High)\n",
    "model <- lm(high ~ ., data = data_for_regression)\n",
    "summary(model)\n",
    "\n",
    "# Lasso\n",
    "install.packages(\"glmnet\")\n",
    "library(glmnet)\n",
    "\n",
    "X <- as.matrix(data[, c(\"Low\", \"Open\", \"Close\", \"Volume\")])\n",
    "y <- as.vector(data$High)\n",
    "\n",
    "X <- scale(X)\n",
    "\n",
    "lambda_values <- 10^seq(10, -2, length = 100)\n",
    "lasso_model <- cv.glmnet(X, y, alpha = 1, lambda = lambda_values)\n",
    "plot(lasso_model)\n",
    "optimal_lambda <- lasso_model$lambda.min\n",
    "final_lasso_model <- glmnet(X, y, alpha = 1, lambda = optimal_lambda)\n",
    "final_lasso_model\n",
    "coefficients <- coef(final_lasso_model)\n",
    "print(coefficients)\n",
    "summary(final_lasso_model)\n",
    "cv.glmnet(X, y, alpha = 1)$cvm[which.min(cv.glmnet(X, y, alpha = 1)$lambda)]\n",
    "\n",
    "A <- as.matrix(data[, c(\"average\", \"Volume\")])\n",
    "A <- scale(A)\n",
    "\n",
    "cv.glmnet(A, y, alpha = 1)$cvm[which.min(cv.glmnet(A, y, alpha = 1)$lambda)]\n",
    "\n",
    "#Residuals \n",
    "residuals <- y - predict(final_lasso_model, newx = X, s = optimal_lambda)\n",
    "plot(predict(final_lasso_model, newx = X, s = optimal_lambda), residuals, \n",
    "     main = \"Lasso Regression Residual Plot\", xlab = \"Fitted Values\", ylab = \"Residuals\")\n",
    "abline(h = 0, col = \"red\", lty = 2)\n",
    "# Create Q-Q plot\n",
    "qqnorm(residuals)\n",
    "qqline(residuals, col = \"red\")\n",
    "\n",
    "# Baseline\n",
    "mean_high = mean(data$High)\n",
    "baseline_predictions = rep(mean_high, nrow(data[3:5]))\n",
    "baseline_mse = mean((data$High - baseline_predictions)^2)\n",
    "baseline_mse\n",
    "\n",
    "# Corrplot\n",
    "clean_data = data[, -(1)]\n",
    "library(corrplot) # activating the corrplot package\n",
    "corrplot(cor(clean_data))\n",
    "\n",
    "# Scatter Matrix\n",
    "install.packages(\"ggplot2\")\n",
    "install.packages(\"GGally\")\n",
    "library(ggplot2) \n",
    "library(GGally) \n",
    "Scatter_Matrix = ggpairs(data,columns = c(2:6), \n",
    "                          title = \"Scatter Plot Matrix for Yahoo Stock Prediction\", \n",
    "                          axisLabels = \"show\") \n",
    "Scatter_Matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Time Series\n",
    "Yahoo_Data = data[2]\n",
    "plot(ts(Yahoo_Data))\n",
    "\n",
    "time = 1:1460\n",
    "model1 = lm(high~time)\n",
    "plot(time,high,type='l')\n",
    "\n",
    "abline(model1,col='red')\n",
    "\n",
    "# Diagnostics\n",
    "count = ts(na.omit(high), frequency = 365)\n",
    "decomp = stl(count, 'periodic')\n",
    "deseasonal = seasadj(decomp)\n",
    "plot(decomp)\n",
    "plot(deseasonal)\n",
    "\n",
    "library(forecast)\n",
    "checkresiduals(ts(Yahoo_Data))\n",
    "\n",
    "# Seasonal\n",
    "ts <- ts(high, frequency = 365)\n",
    "plot(ts)\n",
    "decomposition <- stl(ts, s.window = \"periodic\")\n",
    "seasonal_component <- decomposition$time.series[, \"seasonal\"]\n",
    "plot(seasonal_component)\n",
    "\n",
    "summary(model1)\n",
    "\n",
    "library(lmtest)\n",
    "dwtest(ts(Yahoo_Data))\n",
    "\n",
    "plot(density(residuals(model1)))\n",
    "abline(0,0)\n",
    "\n",
    "plot((ts(Yahoo_Data)))\n",
    "\n",
    "checkresiduals(ts(Yahoo_Data))\n",
    "\n",
    "plot(fitted(high), res)\n",
    "\n",
    "qqnorm(residuals(model1))\n",
    "qqline(residuals(model1), col='red')\n",
    "\n",
    "# Box Jenkins\n",
    "install.packages(\"forecast\")\n",
    "library(forecast)\n",
    "\n",
    "plot(ts(Yahoo_Data))\n",
    "abline(model1,col='red')\n",
    "\n",
    "\n",
    "ts_data = ts(return_data$Return)\n",
    "plot(ts_data)\n",
    "model2 = lm(return_data$Return~return_data$Time)\n",
    "abline(model2,col='red')\n",
    "\n",
    "\n",
    "summary(ts_data)\n",
    "arima_model = auto.arima(ts_data)\n",
    "summary(arima_model)\n",
    "forecast_result = forecast(arima_model, h = 375)\n",
    "plot(forecast_result)\n",
    "\n",
    "#diff_data = diff(ts_data,differences=)\n",
    "acf(ts_data)\n",
    "pacf(diff(ts_data, differences=2))\n",
    "arima_final = auto.arima(ts_data)\n",
    "summary(arima_final)\n",
    "\n",
    "\n",
    "residuals_arima <- residuals(arima_final)\n",
    "durbin_watson_stat <- sum(diff(residuals_arima)^2) / sum(residuals_arima^2)       \n",
    "durbin_watson_stat\n",
    "\n",
    "plot(arima_model$residuals)\n",
    "\n",
    "diff_data=diff(ts_data,differences=1)\n",
    "plot(diff_data, main = \"First Order Differences Plot\")\n",
    "\n",
    "fit = arima(ts_data, order = c(0, 0, 1))\n",
    "summary(fit)\n",
    "tsdiag(fit)\n",
    "\n",
    "# Histogram\n",
    "hist(high, prob = TRUE,\n",
    "     main = \"Histogram\", col = \"blue\", xlim=c(1845,3650), xlab = \"High\", ylim=c(0,0.0011))\n",
    "\n",
    "\n",
    "lines(density(high), col = \"green\", lwd = 3)\n",
    "\n",
    "r=return_data$Return\n",
    "ts_model = ts(r)\n",
    "plot(ts(return_data$Return), ylab = 'Return')\n",
    "checkresiduals(ts_data)\n",
    "plot(residuals(ts_model))\n",
    "\n",
    "residuals <- residuals(arima_final)\n",
    "residuals <- log(residuals(arima_final) + 1)\n",
    "hist(residuals, main = \"Histogram of Residuals\")\n",
    "lines(density(residuals), col = \"blue\")\n",
    "\n",
    "qqnorm(residuals)\n",
    "qqline(residuals)\n",
    "\n",
    "shapiro.test(residuals)\n",
    "\n",
    "install.packages(\"nortest\")\n",
    "library(nortest)  # You may need to install and load the 'nortest' package\n",
    "ad.test(residuals)\n",
    "\n",
    "# wo outliers\n",
    "z_scores <- scale(return_data[2])\n",
    "your_data_no_outliers <- return_data[2][abs(z_scores) < 3]\n",
    "ts_data = ts(your_data_no_outliers)\n",
    "plot(wo_data)\n",
    "acf(ts_data, main=\"Autocorrelation Function for z\")\n",
    "pacf(ts_data, main=\"Partial Autocorrelation Function for z\")\n",
    "arima_try = auto.arima(wo_data)\n",
    "summary(arima_try)\n",
    "\n",
    "residuals1 <- log(residuals(arima_try) + 1)\n",
    "hist(residuals1, main = \"Histogram of Residuals\")\n",
    "lines(density(residuals1), col = \"blue\")\n",
    "\n",
    "qqnorm(residuals1)\n",
    "qqline(residuals1)\n",
    "\n",
    "shapiro.test(residuals1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd35bcb-2cd3-4a05-b7b4-af49172746d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}